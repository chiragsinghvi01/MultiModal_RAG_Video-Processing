{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40353970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from yt_dlp import YoutubeDL\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddf0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csing\\VSCode\\Projects\\MultiModal_RAG_Video-Processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "os.environ[\"OPEN_API_KEY\"] = OPEN_API_KEY\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4337d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://youtu.be/sw_IK4M7S0A?si=FT_ZFohHnGmzaMHp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = \"./video_data/\"\n",
    "output_folder = \"./mixed_data/\"\n",
    "output_audio_path = \"./mixed_data/output_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31887084",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = output_video_path + \"input_vid.mp4\"\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38b14f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(url, output_path):\n",
    "    options = {\n",
    "        'outtmpl': f'{output_path}/input_vid.%(ext)s',\n",
    "        'format': 'best[ext=mp4]/best',  # Prefer mp4 format to avoid merging\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(options) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        metadata = {\n",
    "            \"Author\": info.get(\"uploader\"),\n",
    "            \"Title\": info.get(\"title\"),\n",
    "            \"Views\": info.get(\"view_count\"),\n",
    "            \"Duration\": info.get(\"duration\"),\n",
    "        }\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b2dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(video_path, output_folder):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.write_images_sequence(os.path.join(output_folder, \"frame_%04d.png\"), fps=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5d3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio(video_path, output_audio_path):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    audio = clip.audio\n",
    "    audio.write_audiofile(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f812f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio=sr.AudioFile(audio_path)\n",
    "\n",
    "    with audio as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_whisper(audio_data)\n",
    "        \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Audio not recognized\")         \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9067c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "metadata_vid = download_video(video_url, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecad0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "video_to_images(filepath, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6625eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./mixed_data/output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_to_audio(filepath, output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f4349c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e6f86dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" If you're building AI apps that use custom data, choosing the right framework can save you weeks of development time. In 2025, two top contenders are Langchain and Lama Index. Both are powerful, but they serve slightly different needs. Let's break it down. First, let's talk about ease of use. Lama Index is known for being beginner-friendly. It focuses on helping you connect LLMs with your data. Think PDFs, databases, or notion pages. Using simple Python code. Reviews on GitHub and G2 highlight how easy it is to get started. Even for solo developers or startups. Langchain, on the other hand, is more flexible, but also more complex. It offers chains, agents, tools, and memory systems to build dynamic apps. Developers love the modularity, but reviews on Reddit and TrustPilot note the steep learning curve and sometimes inconsistent documentation. Now, let's talk features and customization. Langchain is built for advanced use cases. Multi-step reasoning, agent workflows, and integration with tools like OpenAI, Pinecon, and Zepier. If you're building a complex AI assistant or multi-agent system, Langchain gives you full control. Lama Index focuses more on retrieval augmented generation, or R-A-G. It shines when you need to feed your LLM context from your own documents. It supports advanced chunking indexing and hybrid search out of the box. Developers love how fast they can go from zero to working prototype. Now pricing and scalability. Both are open-source with active communities, but Langchain has added enterprise features like Langsmith for debugging and monitoring. That's a bonus if you are scaling. Lama Index also introduced enterprise tools in 2025, including fine tuning support and better observability. On G2, teams say it's more cost-effective if you're just focused on retrieval pipelines. Finally, let's talk integration. Langchain integrates with everything, open AI, anthropic, hugging face, vector, db's, and cloud functions. It's the most extensible hands-down. Lama Index also integrates well, but is more open-united. It's built around data connectors and retrievers. If your goal is connecting data to an LLM fast, Lama Index usually wins. So in the end, which one is better? Use Langchain if you're building complex AI workflows, agents, or full stack LLM apps. But if you want a faster, simpler way to plug your data into an LLM, Lama Index is the better pick.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27f80163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data saved to text_data.txt\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(output_folder, \"text_data.txt\"), \"w\") as f:\n",
    "    f.write(text_data)\n",
    "    print(\"Text data saved to text_data.txt\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb88bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file removed after processing.\n"
     ]
    }
   ],
   "source": [
    "os.remove(output_audio_path)\n",
    "print(\"Audio file removed after processing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
